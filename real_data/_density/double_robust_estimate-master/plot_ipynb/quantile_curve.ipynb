{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from dopamine.agents.dqn import dqn_agent\n",
    "from dopamine.agents.implicit_quantile import implicit_quantile_agent\n",
    "from dopamine.agents.rainbow import rainbow_agent\n",
    "from dopamine.agents.tbiqn import tbiqn_agent\n",
    "from dopamine.discrete_domains import atari_lib\n",
    "from dopamine.discrete_domains import checkpointer\n",
    "from dopamine.discrete_domains import iteration_statistics\n",
    "from dopamine.discrete_domains import logger\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gin.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_atari_environment(game_name=None, sticky_actions=True):\n",
    "  assert game_name is not None\n",
    "  game_version = 'v0' if sticky_actions else 'v4'\n",
    "  full_game_name = '{}NoFrameskip-{}'.format(game_name, game_version)\n",
    "  env = gym.make(full_game_name)\n",
    "  # Strip out the TimeLimit wrapper from Gym, which caps us at 100k frames. We\n",
    "  # handle this time limit internally instead, which lets us cap at 108k frames\n",
    "  # (30 minutes). The TimeLimit wrapper also plays poorly with saving and\n",
    "  # restoring states.\n",
    "  env = env.env\n",
    "  env = AtariPreprocessing(env)\n",
    "  return env\n",
    "def initialize_checkpointer_and_maybe_resume(checkpoint_file_prefix):\n",
    "    \"\"\"Reloads the latest checkpoint if it exists.\n",
    "\n",
    "    This method will first create a `Checkpointer` object and then call\n",
    "    `checkpointer.get_latest_checkpoint_number` to determine if there is a valid\n",
    "    checkpoint in self._checkpoint_dir, and what the largest file number is.\n",
    "    If a valid checkpoint file is found, it will load the bundled data from this\n",
    "    file and will pass it to the agent for it to reload its data.\n",
    "    If the agent is able to successfully unbundle, this method will verify that\n",
    "    the unbundled data contains the keys,'logs' and 'current_iteration'. It will\n",
    "    then load the `Logger`'s data from the bundle, and will return the iteration\n",
    "    number keyed by 'current_iteration' as one of the return values (along with\n",
    "    the `Checkpointer` object).\n",
    "\n",
    "    Args:\n",
    "      checkpoint_file_prefix: str, the checkpoint file prefix.\n",
    "\n",
    "    Returns:\n",
    "      start_iteration: int, the iteration number to start the experiment from.\n",
    "      experiment_checkpointer: `Checkpointer` object for the experiment.\n",
    "    \"\"\"\n",
    "    checkpointer = checkpointer.Checkpointer(self._checkpoint_dir,\n",
    "                                                   checkpoint_file_prefix)\n",
    "    self._start_iteration = 0\n",
    "    # Check if checkpoint exists. Note that the existence of checkpoint 0 means\n",
    "    # that we have finished iteration 0 (so we will start from iteration 1).\n",
    "    latest_checkpoint_version = checkpointer.get_latest_checkpoint_number(\n",
    "        self._checkpoint_dir)\n",
    "    if latest_checkpoint_version >= 0:\n",
    "      experiment_data = self._checkpointer.load_checkpoint(\n",
    "          latest_checkpoint_version)\n",
    "      if self._agent.unbundle(\n",
    "          self._checkpoint_dir, latest_checkpoint_version, experiment_data):\n",
    "        if experiment_data is not None:\n",
    "          assert 'logs' in experiment_data\n",
    "          assert 'current_iteration' in experiment_data\n",
    "          self._logger.data = experiment_data['logs']\n",
    "          self._start_iteration = experiment_data['current_iteration'] + 1\n",
    "        tf.logging.info('Reloaded checkpoint and will start from iteration %d',\n",
    "                        self._start_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamename = 'StarGunner'\n",
    "\n",
    "base_dir = 'tmp/test'\n",
    "checkpoint_dir = 'expriment/k64/stargunner/checkpoints'\n",
    "summary_writer = tf.summary.FileWriter(base_dir)\n",
    "environment = atari_lib.create_atari_environment(gamename)\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session('', config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating TbImplicitQuantileAgent agent with the following parameters:\n",
      "INFO:tensorflow:\t gamma: 0.990000\n",
      "INFO:tensorflow:\t update_horizon: 1.000000\n",
      "INFO:tensorflow:\t min_replay_history: 20000\n",
      "INFO:tensorflow:\t update_period: 4\n",
      "INFO:tensorflow:\t target_update_period: 8000\n",
      "INFO:tensorflow:\t epsilon_train: 0.010000\n",
      "INFO:tensorflow:\t epsilon_eval: 0.001000\n",
      "INFO:tensorflow:\t epsilon_decay_period: 250000\n",
      "INFO:tensorflow:\t tf_device: /cpu:*\n",
      "INFO:tensorflow:\t use_staging: True\n",
      "INFO:tensorflow:\t optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f516587a860>\n",
      "INFO:tensorflow:\t max_tf_checkpoints_to_keep: 4\n",
      "INFO:tensorflow:Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:\n",
      "INFO:tensorflow:\t observation_shape: (84, 84)\n",
      "INFO:tensorflow:\t observation_dtype: <class 'numpy.uint8'>\n",
      "INFO:tensorflow:\t terminal_dtype: <class 'numpy.uint8'>\n",
      "INFO:tensorflow:\t stack_size: 4\n",
      "INFO:tensorflow:\t replay_capacity: 1000000\n",
      "INFO:tensorflow:\t batch_size: 32\n",
      "INFO:tensorflow:\t update_horizon: 1\n",
      "INFO:tensorflow:\t gamma: 0.990000\n",
      "WARNING:tensorflow:From /home/sufedc_nvidia_wangjianing/dopamine/dopamine/replay_memory/circular_replay_buffer.py:821: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:From /home/sufedc_nvidia_wangjianing/dopamine/dopamine/discrete_domains/atari_lib.py:639: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sufedc_nvidia_wangjianing/anaconda3/envs/dopamine-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f5164318ba8>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TbImplicitQuantileNetwork.call of <dopamine.discrete_domains.atari_lib.TbImplicitQuantileNetwork object at 0x7f51600eb048>>, which Python reported as:\n",
      "  def call(self, state, num_quantiles):\n",
      "    \"\"\"Creates the output tensor/op given the state tensor as input.\n",
      "\n",
      "    See https://www.tensorflow.org/api_docs/python/tf/keras/Model for more\n",
      "    information on this. Note that tf.keras.Model implements `call` which is\n",
      "    wrapped by `__call__` function by tf.keras.Model.\n",
      "\n",
      "    Args:\n",
      "      state: `tf.Tensor`, contains the agent's current state.\n",
      "      num_quantiles: int, number of quantile inputs.\n",
      "    Returns:\n",
      "      collections.namedtuple, that contains (quantile_values, quantiles).\n",
      "    \"\"\"\n",
      "    batch_size = state.get_shape().as_list()[0]\n",
      "    x = tf.cast(state, tf.float32)\n",
      "    x = tf.div(x, 255.)\n",
      "    x = self.conv1(x)\n",
      "    x = self.conv2(x)\n",
      "    x = self.conv3(x)\n",
      "    x = self.flatten(x)\n",
      "    weight = self.weight1(x)\n",
      "    weight = tf.reshape(self.weight2(weight),[batch_size, 2,self.num_actions])\n",
      "    \n",
      "    state_vector_length = x.get_shape().as_list()[-1]#(batch,7*7*64)\n",
      "    state_net_tiled = tf.tile(tf.expand_dims(x,axis=1), [1,num_quantiles, 1])#(batch,num_quantiles,7*7*64)\n",
      "#     quantiles_shape = [num_quantiles * batch_size, 1]\n",
      "    quantiles = tf.random_uniform(\n",
      "        [batch_size,num_quantiles,1], minval=0, maxval=1, dtype=tf.float32)\n",
      "    quantiles = tf.sort(quantiles,axis=1)\n",
      "    quantile_net = tf.tile(quantiles, [1, 1,self.quantile_embedding_dim])#shape(batch_size,num_quantiles  ,self.quantile_embedding_dim)\n",
      "    pi = tf.constant(math.pi)\n",
      "    quantile_net = tf.cast(tf.range(\n",
      "        1, self.quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
      "    quantile_net = tf.cos(quantile_net)\n",
      "    # Create the quantile layer in the first call. This is because\n",
      "    # number of output units depends on the input shape. Therefore, we can only\n",
      "    # create the layer during the first forward call, not during `.__init__()`.\n",
      "    if not hasattr(self, 'dense_quantile'):\n",
      "      self.dense_quantile = tf.keras.layers.Dense(\n",
      "          state_vector_length, activation=self.activation_fn,\n",
      "          kernel_initializer=self.kernel_initializer)\n",
      "    quantile_net = self.dense_quantile(quantile_net)#( batch_size,num_quantiles ,7*7*64)\n",
      "    x = tf.multiply(state_net_tiled, quantile_net)\n",
      "    x = self.dense1(x)#(batch_size,num_quantiles ,512)\n",
      "    quantile_values = self.dense2(x)#( batch_size,num_quantiles ,num_actions)\n",
      "    \n",
      "    w = tf.tile(tf.expand_dims(weight[:,0,:],axis=1),[1,num_quantiles,1])\n",
      "    b = tf.tile(tf.expand_dims(weight[:,1,:],axis=1),[1,num_quantiles,1])\n",
      "    probs = tf.cumsum(self.softmax(quantile_values),axis=1)\n",
      "    quantile_values = tf.add(tf.multiply(probs,w),b)\n",
      "\n",
      "    return TbImplicitQuantileNetworkType(quantile_values, quantiles)\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sufedc_nvidia_wangjianing/dopamine/dopamine/agents/tbiqn/tbiqn_agent.py:186: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/sufedc_nvidia_wangjianing/anaconda3/envs/dopamine-env/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/sufedc_nvidia_wangjianing/dopamine/dopamine/agents/dqn/dqn_agent.py:207: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "INFO:tensorflow:legacy_checkpoint_load: False\n"
     ]
    }
   ],
   "source": [
    "agent = tbiqn_agent.TbImplicitQuantileAgent(\n",
    "    sess=sess,\n",
    "    network=atari_lib.TbImplicitQuantileNetwork,\n",
    "    num_actions=environment.action_space.n,\n",
    "    kappa=1.0,\n",
    "    num_tau_samples=64,\n",
    "    num_tau_prime_samples=64,\n",
    "    num_quantile_samples=64)\n",
    "agent.eval_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dopamine.discrete_domains import checkpointer\n",
    "checkpointers = checkpointer.Checkpointer(checkpoint_dir,'ckpt')\n",
    "start_iteration = 0\n",
    "# Check if checkpoint exists. Note that the existence of checkpoint 0 means\n",
    "# that we have finished iteration 0 (so we will start from iteration 1).\n",
    "latest_checkpoint_version = checkpointer.get_latest_checkpoint_number(checkpoint_dir)\n",
    "latest_checkpoint_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from expriment/k64/stargunner/checkpoints/tf_ckpt-20\n"
     ]
    }
   ],
   "source": [
    "if latest_checkpoint_version >= 0:\n",
    "    experiment_data = checkpointers.load_checkpoint(\n",
    "      latest_checkpoint_version)\n",
    "    if agent._saver.restore(agent._sess,\n",
    "                        os.path.join(checkpoint_dir,\n",
    "                                     'tf_ckpt-{}'.format(latest_checkpoint_version))):\n",
    "\n",
    "        if experiment_data is not None:\n",
    "            assert 'logs' in experiment_data\n",
    "            assert 'current_iteration' in experiment_data\n",
    "#             logger.data = experiment_data['logs']\n",
    "            start_iteration = experiment_data['current_iteration'] + 1\n",
    "        tf.logging.info('Reloaded checkpoint and will start from iteration %d',\n",
    "                    start_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_episode(environment,agent):\n",
    "\n",
    "    initial_observation = environment.reset()\n",
    "    return agent.begin_episode(initial_observation)\n",
    "\n",
    "def run_one_step(environment,action):\n",
    "    \"\"\"Executes a single step in the environment.\n",
    "\n",
    "    Args:\n",
    "      action: int, the action to perform in the environment.\n",
    "\n",
    "    Returns:\n",
    "      The observation, reward, and is_terminal values returned from the\n",
    "        environment.\n",
    "    \"\"\"\n",
    "    observation, reward, is_terminal, _ = environment.step(action)\n",
    "    return observation, reward, is_terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = initialize_episode(environment,agent)\n",
    "observation, reward, is_terminal = run_one_step(environment,action)\n",
    "\n",
    "agent._last_observation = agent._observation\n",
    "agent._record_observation(observation)\n",
    "a = sess.run(agent._net_outputs,{agent.state_ph: agent.state})\n",
    "\n",
    "output_ph = agent.online_convnet(agent.state_ph,64)\n",
    "b = sess.run(output_ph,{agent.state_ph:agent.state})\n",
    "# print(a[0][0][:,0])\n",
    "q = np.concatenate([a[0],b[0]],axis=1)[0]\n",
    "taus = a[1][0][:,0]\n",
    "taus1 = b[1][0][:,0]\n",
    "tau = np.concatenate([taus,taus1],axis=0)\n",
    "show = q[:,0][np.argsort(tau.squeeze())]\n",
    "# print(tau.squeeze().shape)\n",
    "# # np.argsort(show[])\n",
    "# # print(np.argsort(tau).shape)\n",
    "plt.plot(np.sort(taus),a[0][0,:,0],label='64')\n",
    "plt.plot(np.sort(taus1),b[0][0,:,0],label='32')\n",
    "plt.plot(np.sort(tau.squeeze()),show,label='all')\n",
    "# import matplotlib.pyplot as plt \n",
    "# plt.imshow(agent.state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(taus),a[0][0,:,0],label='64')\n",
    "plt.plot(np.sort(taus1),b[0][0,:,0],label='32')\n",
    "plt.plot(np.sort(tau.squeeze()),show,label='all')\n",
    "# plt.legend()\n",
    "print(taus1.shape)\n",
    "# import matplotlib.pyplot as plt \n",
    "# plt.imshow(agent.state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00769231 0.02307692 0.03846154 0.05384615 0.06923077 0.08461539\n",
      "  0.1        0.11538462 0.13076924 0.14615385 0.16153847 0.17692308\n",
      "  0.1923077  0.20769231 0.22307692 0.23846154 0.25384617 0.26923078\n",
      "  0.2846154  0.3        0.31538463 0.33076924 0.34615386 0.36153847\n",
      "  0.37692308 0.3923077  0.4076923  0.42307693 0.43846154 0.45384616\n",
      "  0.46923077 0.4846154  0.5        0.5153847  0.5307692  0.5461539\n",
      "  0.56153846 0.57692313 0.5923077  0.60769236 0.6230769  0.6384616\n",
      "  0.65384614 0.6692308  0.6846154  0.70000005 0.7153846  0.7307693\n",
      "  0.74615383 0.7615385  0.77692306 0.79230773 0.8076923  0.82307696\n",
      "  0.8384615  0.8538462  0.86923075 0.8846154  0.9        0.91538465\n",
      "  0.9307692  0.9461539  0.96153843 0.9769231 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = tf.range(0, 1,1/(64 + 1))\n",
    "quantiles = tf.expand_dims((quantiles[:64]+quantiles[1:64+1])/2,0)\n",
    "sess = tf.Session()\n",
    "print(sess.run(quantiles))\n",
    "sess.run(quantiles).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Tile_4:0\", shape=(32, 64), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02307692, 0.03846154, 0.05384615, ..., 0.96153843, 0.9769231 ,\n",
       "        0.99230766],\n",
       "       [0.02307692, 0.03846154, 0.05384615, ..., 0.96153843, 0.9769231 ,\n",
       "        0.99230766],\n",
       "       [0.02307692, 0.03846154, 0.05384615, ..., 0.96153843, 0.9769231 ,\n",
       "        0.99230766],\n",
       "       ...,\n",
       "       [0.02307692, 0.03846154, 0.05384615, ..., 0.96153843, 0.9769231 ,\n",
       "        0.99230766],\n",
       "       [0.02307692, 0.03846154, 0.05384615, ..., 0.96153843, 0.9769231 ,\n",
       "        0.99230766],\n",
       "       [0.02307692, 0.03846154, 0.05384615, ..., 0.96153843, 0.9769231 ,\n",
       "        0.99230766]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_quantile_samples = 64\n",
    "quantiles = tf.range(0, 1,1/(num_quantile_samples+1) )+1/(num_quantile_samples+1)\n",
    "quantiles = tf.expand_dims((quantiles[:num_quantile_samples]+quantiles[1:num_quantile_samples+1])/2,0)\n",
    "# quantiles = tf.expand_dims(quantiles,0)\n",
    "quantiles = tf.tile(quantiles, [32, 1])\n",
    "print(quantiles)\n",
    "sess= tf.Session()\n",
    "sess.run(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31250.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "250000/8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dopamine-env",
   "language": "python",
   "name": "dopamine-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

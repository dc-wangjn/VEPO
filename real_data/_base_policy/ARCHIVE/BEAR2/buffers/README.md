# BEAR-QL Dataset 

The authors made three kinds of datasets: optimal, medium-quality, random datasets; for four different Mujoco environments: HalfCheetah-v2, Walker2d-v2, Hopper-v2, and Ant-v2. The optimal and medium quality dataset are generated by rolling a policy trained by Soft Actor-Critic (SAC) algorithm. As denoted by the paper, the official implementation of [Soft Actor-Critic (SAC)](https://github.com/rail-berkeley/softlearning) algorithm is used to generate optimal and medium-quality datasets. Random dataset is generated by rolling uniform policy. You can directly download datasets used in the experiments.

|Data        |                             Link                             |
| :-----------: | :----------------------------------------------------------: |
|Optimal| [Dropbox](https://www.dropbox.com/sh/4mb6n2qxr0xogpi/AACIJDhjZT9Ia1OS_A8oxrQga?dl=0)|
|Medium | [Dropbox](https://www.dropbox.com/sh/uhjtflggq59xe6a/AAB3YhWb_Z3OfyX7HGdts7JVa?dl=0)|
|Random | [Dropbox](https://www.dropbox.com/sh/2s1tybbypyexltu/AABMFHrCNSdwj2qyZ412sWdua?dl=0)|

The average return with standard deviation(±%) of the behavior policy of each dataset is provided below. 

|Data        |HalfCheetah-v2|Walker2d-v2|Hopper-v2|Ant-v2|
| :-----------: |:---------:|:---------:|:---------:|:---------:|
|Optimal|12254 ±2% | 3146 ±22%|2695 ±0.7%| 5193 ±9%|
|Medium | 3995 ±11%| 510 ±46% | 1119 ±8% | 614 ±45%|
|Random | 0 | 0 | 0 | 0 |
